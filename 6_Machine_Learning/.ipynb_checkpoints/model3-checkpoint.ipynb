{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595bed85-7663-43bf-985e-46018621a77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a80000c-cd55-41c5-aa3d-3a624cf4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02743c4-4f60-497e-9a1a-5081b2c083db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/upadesh/3_Codes/6_Au_Au_Laser/1_Simulation_Results/ML_numpy_files'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = os.path.abspath('data/')\n",
    "path = os.path.abspath('../1_Simulation_Results/ML_numpy_files/')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb3a88e-b813-4aab-b95c-eb0742a67e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.load(path+'/X.npy'), np.load(path+'/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a7f3c6-1a8a-4dd8-b508-a420eecc6eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1623, 201, 401), (1623, 201, 401))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3492eeb7-2b6e-4368-a3c3-f0884f6df60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 401)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa = X[200]\n",
    "np.save('data/Xa.npy', Xa)\n",
    "Xa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1afd6618-1b7c-448c-8a44-704e45f171e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 201, 401)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_a = Xa[np.newaxis, np.newaxis, :, :] \n",
    "X_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819e372d-3de8-4787-b6e0-038292619a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(Xa, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for your test set\n",
    "test_dataset = TensorDataset(test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bec73cf7-11b0-4943-aa56-f14712c99446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "torch.Size([1, 401])\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in test_loader:\n",
    "    print((i[0].shape))\n",
    "    a+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da279a6e-aae6-4699-a682-5e4238f8b5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c23e2-1a01-4d98-a098-0ed0d56a0f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73afccf2-8e20-4cd4-a34f-0130a68bdc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1b05e3-b634-4535-a411-53a22dc57811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X and y to match PyTorch's Conv2d input format: (batch_size, channels, width, height)\n",
    "X_reshaped = X[:, np.newaxis, :, :] \n",
    "y_reshaped = y[:, np.newaxis, :, :] \n",
    "\n",
    "# Split data into training, testing, validation sets\n",
    "X_, X_test, y_, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.1, random_state=69)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.109, random_state=69)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1cafe8f-98cb-4c06-9d83-01dd014aed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature [batch, channel, width, height] => Train: torch.Size([1300, 1, 201, 401]) | Test: torch.Size([163, 1, 201, 401]) | Validation torch.Size([160, 1, 201, 401])\n",
      "Label   [batch, channel, width, height] => Train: torch.Size([1300, 1, 201, 401]) | Test: torch.Size([163, 1, 201, 401]) | Validation torch.Size([160, 1, 201, 401])\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature [batch, channel, width, height] => Train: {X_train.shape} | Test: {X_test.shape} | Validation {X_val.shape}')\n",
    "print(f'Label   [batch, channel, width, height] => Train: {y_train.shape} | Test: {y_test.shape} | Validation {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61904dff-5a59-45e5-b08d-c47eba22b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data/X_test.npy', X_test)\n",
    "# np.save('data/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95b1ce-9673-4c82-8a39-8a08353fe6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1be850-5583-42ac-9f53-4963edab47a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3a2758-6069-4f1c-8a5d-cb030ca319fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet model definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.middle = conv_block(512, 1024)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "\n",
    "        middle = self.middle(self.pool(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(middle)\n",
    "        dec4 = self.pad_and_crop(enc4, dec4)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = self.pad_and_crop(enc3, dec3)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = self.pad_and_crop(enc2, dec2)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = self.pad_and_crop(enc1, dec1)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        out = self.final(dec1)\n",
    "        return out\n",
    "\n",
    "    def pad_and_crop(self, target, tensor):\n",
    "        _, _, target_height, target_width = target.size()\n",
    "        _, _, tensor_height, tensor_width = tensor.size()\n",
    "\n",
    "        # Padding\n",
    "        pad_h = max(0, target_height - tensor_height)\n",
    "        pad_w = max(0, target_width - tensor_width)\n",
    "\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "\n",
    "        tensor = F.pad(tensor, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0)\n",
    "\n",
    "        # Cropping\n",
    "        delta_h = (tensor.size(2) - target_height) // 2\n",
    "        delta_w = (tensor.size(3) - target_width) // 2\n",
    "\n",
    "        return tensor[:, :, delta_h: delta_h + target_height, delta_w: delta_w + target_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec38bef-c55f-4204-b2f2-431e112db760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        # label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        feature = self.features[idx].clone().detach().requires_grad_(True)\n",
    "        label = self.labels[idx].clone().detach()\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0adbd259-b121-4651-9a58-530402845097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy (for binary classification)\n",
    "def calculate_accuracy(output, target):\n",
    "    preds = torch.sigmoid(output) > 0.5\n",
    "    correct = (preds == target).float()\n",
    "    acc = correct.sum() / torch.numel(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41062139-7305-4fd0-bbd9-2913a73241cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loaders\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=13, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=13, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=13, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04e5694-458d-4a3f-9c42-f33d6e61aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom progress bar function\n",
    "def show_progress_bar(current, total, bar_length=20):\n",
    "    \"\"\"Displays a progress bar with arrows.\"\"\"\n",
    "    fraction = current / total\n",
    "    arrow_count = int(fraction * bar_length)\n",
    "    bar = '=' * arrow_count + '>' + ' ' * (bar_length - arrow_count - 1)\n",
    "    progress_message = f'[{bar}] {current}/{total} batches'\n",
    "    print(progress_message, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afbc9f84-80a8-4b94-9262-98f9629914c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with validation\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, history_path='training_history.npy'):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    bar_length = 20  # Length of the progress bar\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "\n",
    "            # Show custom progress bar\n",
    "            show_progress_bar(i + 1, len(train_loader), bar_length)\n",
    "\n",
    "        print()  # New line after the progress bar\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = running_acc / len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_acc / len(val_loader.dataset)\n",
    "\n",
    "        # Store loss and accuracy for this epoch\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, \"\n",
    "              f\"Train Acc: {epoch_train_acc:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    # Save training history to a numpy file\n",
    "    np.save(history_path, history)\n",
    "    print(f'Training history saved to {history_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e007e729-c691-4c5b-badd-88707e7d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function for losses and accuracies\n",
    "def plot_training_history(history_path='training_history.npy'):\n",
    "    history = np.load(history_path, allow_pickle=True).item()\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plotting loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b', label='Training Loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1c4a85-9d5f-42a2-82d7-2485fe5107f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, optimizer\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4596c-c734-41eb-9b84-8f03de5c7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193820/243389034.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
      "/tmp/ipykernel_193820/243389034.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=>                  ] 9/100 batches\r"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 25\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84246825-f650-4fc8-abf4-7bfecbdfa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27fe18-61f4-4253-89c4-01af2854c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Unet_model3.pth')\n",
    "print('Model saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc815b-f27f-4ce8-951b-a334880dfffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model\n",
    "model = torch.load('model.pth')\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccc2ea-d056-43d2-b5f1-6c5223fcccb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78180096-9f28-4184-9832-32b6dda9093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        test_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "\n",
    "test_loss /= len(test_dataset)\n",
    "test_acc /= len(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {100*test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f969a49-bfff-4584-b222-369e128a7298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e8b6c-0fe1-4594-b55e-6474d384c31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f794d-6c8e-4554-800c-73e0db9c6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your test data is stored in test_features and has shape (num_samples, 1, 201, 401)\n",
    "# Replace test_features with your actual test data array\n",
    "test_features = X_test  # Example data, replace with actual test data\n",
    "\n",
    "# Convert the test features to PyTorch tensors\n",
    "test_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for your test set\n",
    "test_dataset = TensorDataset(test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move model to the correct device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Disable gradient computation for testing\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs[0].to(device)  # Get the input tensor and move it to the device\n",
    "        \n",
    "        # Forward pass to get the output\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities if using BCEWithLogitsLoss\n",
    "        predictions = torch.sigmoid(outputs)\n",
    "        \n",
    "        # Convert probabilities to binary predictions (0 or 1)\n",
    "        predicted_labels = (predictions > 0.5).float()  # Threshold at 0.5\n",
    "        \n",
    "        # Move predictions back to the CPU and convert to numpy\n",
    "        all_predictions.append(predicted_labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all predictions\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# Output predictions\n",
    "print(\"Predictions shape:\", all_predictions.shape)\n",
    "# print(all_predictions)\n",
    "\n",
    "error = all_predictions - np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6d23a-f9b5-43f2-b99f-14270e9e3955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7e60e-e2ea-4947-b68c-80e379fffd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5a761-c169-4963-b8ad-b4590b48c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_step = 0\n",
    "# laser_pos = (125 + time[t_step]*laser_speed)* 401/1000  # Laser actual position in true dimension\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(12,12), frameon=True)\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax1.imshow(all_predictions[t_step][0], cmap=cmap, vmin=0.5, vmax=1.0, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax1.imshow(1-all_predictions[t_step][0], cmap=cmap, vmin=0.5, vmax=1.5, aspect=0.5, interpolation='quadric')\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax2.imshow(y_test[t_step][0] , cmap=cmap, vmin=0.5, vmax=1.0, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax2.imshow(1-y_test[t_step][0], cmap=cmap, vmin=0.5, vmax=1.5, aspect=0.5, interpolation='quadric')\n",
    "\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax3.imshow(error[t_step][0], cmap=cmap, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax3.imshow(1-error[t_step][0], cmap=cmap, aspect=0.5, interpolation='quadric')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46974ec0-7845-4f77-99c4-28e54885d1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc37fe-e542-4ed8-b6fa-16d23f45df2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77135e4-1b3a-4071-ad15-e15c3d6ce590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec7699-65c9-42c7-a850-ccba63eee142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de4d89-853a-40fb-ae49-0c969b6a3ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28c2cb-686d-43c1-86ac-0d46b64d4c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3c4d2-8cbd-4799-8840-ea59e27c3180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83b17b71-ebe6-4a3c-8aac-43a8d8303f10",
   "metadata": {},
   "source": [
    "## 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598229f5-8f23-4fac-a350-5c2218f04730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with validation and progress bar\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "num_epochs = 2  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update()\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    epoch_train_acc = running_acc / len(train_dataset)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_acc / len(val_dataset)\n",
    "    \n",
    "    # Store loss and accuracy for this epoch\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, \"\n",
    "          f\"Train Acc: {epoch_train_acc:.4f}, Val Acc: {epoch_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32668ad-d6b5-4a7e-a604-1142e158dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to a numpy file\n",
    "np.save('training_history.npy', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140109d-5988-4ad3-af6b-f1bcbe9bf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        test_acc += calculate_accuracy(outputs, targets).item() * inputs.size(0)\n",
    "\n",
    "test_loss /= len(test_dataset)\n",
    "test_acc /= len(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd2c3e-4fe8-4ba6-a4e2-38c12820bcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24473769-a147-4595-a6e5-35fadbae5850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3db19-11b9-405a-b8e8-2496617f98f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b7b3e-781d-4324-8dc1-34b58fd13af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4822756-b110-499f-808c-6c3037f21a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77d2d2-b7f4-4b1f-b550-dff8a7b274d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df695e01-25c3-47d3-a783-33336031a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_step = 20\n",
    "# laser_pos = (125 + time[t_step]*laser_speed)* 401/1000  # Laser actual position in true dimension\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(12,12), frameon=True)\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax1.imshow(all_predictions[t_step][0], cmap=cmap, vmin=0.5, vmax=1.0, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax1.imshow(1-all_predictions[t_step][0], cmap=cmap, vmin=0.5, vmax=1.5, aspect=0.5, interpolation='quadric')\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax2.imshow(y_test[t_step][0] , cmap=cmap, vmin=0.5, vmax=1.0, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax2.imshow(1-y_test[t_step][0], cmap=cmap, vmin=0.5, vmax=1.5, aspect=0.5, interpolation='quadric')\n",
    "\n",
    "cmap = plt.get_cmap('RdYlGn_r')\n",
    "cmap.set_under('white', alpha=0)\n",
    "hmap1 = ax3.imshow(error[t_step][0], cmap=cmap, aspect=0.5,  interpolation='quadric')\n",
    "cmap = plt.get_cmap('Wistia')\n",
    "cmap.set_under('white', alpha=0) \n",
    "hmap2 = ax3.imshow(1-error[t_step][0], cmap=cmap, aspect=0.5, interpolation='quadric')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
